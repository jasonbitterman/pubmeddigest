{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from Bio import Entrez\n",
    "import time\n",
    "\n",
    "# Define topic for summary document. Don't be too broad or you will retrieve a very large number of papers.\n",
    "topic = \"hemochromatosis\"  # THOUGHTS - could use LLM to refine topic?\n",
    "topics = [topic]\n",
    "\n",
    "# Define date ranges\n",
    "start_date = \"2024/12/01\"\n",
    "end_date = \"2025/07/05\"\n",
    "date_range = f'(\"{start_date}\"[Date - Create] : \"{end_date}\"[Date - Create])'\n",
    "\n",
    "# Define max number of results to return.\n",
    "# If you plan to search for more than about 15 articles, you will need to create your own Entrez account and generate an API key and enter them below.\n",
    "max_results = 20\n",
    "\n",
    "# Enter your Entrez account email address abd API key. If you plan on only summarizing less than about 15 articles, you can leave these empty.\n",
    "Entrez.email = \"jasonbitt@gmail.com\"  # Enter your email address\n",
    "Entrez.api_key = \"a21f5cd33f0e3f0f0730d4562ebdacdefb09\"  # Enter your Entrez API key (can be generated at https://account.ncbi.nlm.nih.gov/settings/)\n",
    "\n",
    "# Build the query dynamically based on the available topics\n",
    "queries = []\n",
    "\n",
    "if topics:\n",
    "    topic_queries = [\"{}[Title/Abstract]\".format(topic) for topic in topics]\n",
    "    queries.append(\"(\" + \" OR \".join(topic_queries) + \")\")\n",
    "\n",
    "full_query = \" AND \".join(queries) + \" AND \" + date_range\n",
    "\n",
    "# Search PubMed for relevant records\n",
    "handle = Entrez.esearch(db=\"pubmed\", retmax=max_results, term=full_query)\n",
    "record = Entrez.read(handle)\n",
    "id_list = record[\"IdList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Count': '96', 'RetMax': '5', 'RetStart': '0', 'IdList': ['40607335', '40603805', '40603799', '40603795', '40603794'], 'TranslationSet': [], 'QueryTranslation': '\"hemochromatosis\"[Title/Abstract] AND 2024/12/01:2025/07/05[Date - Create]'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from Bio import Entrez\n",
    "import time\n",
    "\n",
    "\n",
    "# DataFrame to store the extracted data\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"PMID\",\n",
    "        \"Title\",\n",
    "        \"Abstract\",\n",
    "        \"Journal\",\n",
    "        \"Keywords\",\n",
    "        \"URL\",\n",
    "        \"PubDate\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fetch information for each record in the id_list\n",
    "for pmid in id_list:\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=pmid, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "\n",
    "    # Process each PubMed article in the response\n",
    "    for record in records[\"PubmedArticle\"]:\n",
    "        # Print the record in a formatted JSON style\n",
    "        # print(\n",
    "        # json.dumps(record, indent=4, default=str)\n",
    "        # )  # default=str handles types JSON can't serialize like datetime\n",
    "\n",
    "        article = record[\"MedlineCitation\"][\"Article\"]\n",
    "\n",
    "        title = article[\"ArticleTitle\"]\n",
    "        abstract = (\n",
    "            \" \".join(article[\"Abstract\"][\"AbstractText\"])\n",
    "            if \"Abstract\" in article and \"AbstractText\" in article[\"Abstract\"]\n",
    "            else \"\"\n",
    "        )\n",
    "\n",
    "        journal_title = article[\"Journal\"][\"Title\"]\n",
    "        keywords = (\n",
    "            \", \".join(\n",
    "                keyword[\"DescriptorName\"]\n",
    "                for keyword in record[\"MedlineCitation\"][\"MeshHeadingList\"]\n",
    "            )\n",
    "            if \"MeshHeadingList\" in record[\"MedlineCitation\"]\n",
    "            else \"\"\n",
    "        )\n",
    "        url = f\"https://www.ncbi.nlm.nih.gov/pubmed/{pmid}\"\n",
    "        pub_date = article[\"Journal\"][\"JournalIssue\"][\"PubDate\"]\n",
    "\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"PMID\": [pmid],\n",
    "                \"Title\": [title],\n",
    "                \"Abstract\": [abstract],\n",
    "                \"Journal\": [journal_title],\n",
    "                \"Keywords\": [keywords],\n",
    "                \"URL\": [url],\n",
    "                \"PubDate\": [pub_date],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    time.sleep(0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PubDate to standardized MM/DD/YYYY format\n",
    "def standardize_date(pub_date):\n",
    "    year = pub_date.get(\"Year\", \"\")\n",
    "    month = pub_date.get(\"Month\", \"01\")\n",
    "    day = pub_date.get(\"Day\", \"01\")\n",
    "\n",
    "    # Convert month name to number if needed\n",
    "    month_map = {\n",
    "        \"Jan\": \"01\",\n",
    "        \"Feb\": \"02\",\n",
    "        \"Mar\": \"03\",\n",
    "        \"Apr\": \"04\",\n",
    "        \"May\": \"05\",\n",
    "        \"Jun\": \"06\",\n",
    "        \"Jul\": \"07\",\n",
    "        \"Aug\": \"08\",\n",
    "        \"Sep\": \"09\",\n",
    "        \"Oct\": \"10\",\n",
    "        \"Nov\": \"11\",\n",
    "        \"Dec\": \"12\",\n",
    "    }\n",
    "    if month in month_map:\n",
    "        month = month_map[month]\n",
    "\n",
    "    # Ensure month and day are 2 digits\n",
    "    month = month.zfill(2)\n",
    "    day = str(day).zfill(2)\n",
    "\n",
    "    return f\"{month}/{day}/{year}\"\n",
    "\n",
    "\n",
    "# Apply the date standardization to the PubDate column\n",
    "df[\"PubDate\"] = df[\"PubDate\"].apply(standardize_date)\n",
    "\n",
    "# Create markdown content\n",
    "markdown_content = \"# PubMed Search Results\\n\\n\"\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    markdown_content += f\"## {row['Title']}\\n\\n\"\n",
    "    markdown_content += f\"**Journal:** {row['Journal']}\\n\\n\"\n",
    "    markdown_content += f\"**Publication Date:** {row['PubDate']}\\n\\n\"\n",
    "    markdown_content += f\"**Keywords:** {row['Keywords']}\\n\\n\"\n",
    "    markdown_content += f\"**Abstract:**\\n{row['Abstract']}\\n\\n\"\n",
    "    markdown_content += f\"**URL:** [{row['URL']})\\n\\n\"\n",
    "    markdown_content += f\"**PMID:** [{row['PMID']}]\\n\\n\"\n",
    "    markdown_content += \"---\\n\\n\"\n",
    "\n",
    "# Save to markdown file\n",
    "with open(\"PubMed_results.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)\n",
    "file_name = \"PubMed_results.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basics for LLM (OpenAI)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-S57pphsZedBRN5D9tK4v6r\n",
      "vs_68745130c6488191a9fe4c24c0b35180\n",
      "\n",
      "\n",
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-S57pphsZedBRN5D9tK4v6r', created_at=1752453426, last_error=None, object='vector_store.file', status='completed', usage_bytes=69570, vector_store_id='vs_68745130c6488191a9fe4c24c0b35180', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-S57pphsZedBRN5D9tK4v6r', last_id='file-S57pphsZedBRN5D9tK4v6r')\n"
     ]
    }
   ],
   "source": [
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(file=file_tuple, purpose=\"assistants\")\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(file=file_content, purpose=\"assistants\")\n",
    "    print(result.id)\n",
    "    return result.id\n",
    "\n",
    "\n",
    "# Replace with your own file path or URL\n",
    "file_id = create_file(client, file_name)\n",
    "\n",
    "# Create a vector store\n",
    "vector_store = client.vector_stores.create(name=\"knowledge_base\")\n",
    "print(vector_store.id)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Add the file to the vector store\n",
    "client.vector_stores.files.create(vector_store_id=vector_store.id, file_id=file_id)\n",
    "\n",
    "result = client.vector_stores.files.list(vector_store_id=vector_store.id)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to 2025-07-13_gabapentin_summary.md\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=\"You are a skilled and detail oriented analyst with a background in data interpretation and technical writing. You have a talent for identifying patterns and extracting meaningful insights from research data, then communicating those insights effectively and succinctly through well-crafted reports. You are creating monthly documents for a medical team the summarizes papers what is new in a specific medical topic.\",\n",
    "    input=\"\"\"Create a summary document titled 'What's New in XXX' (where XXX is the topic of the papers). The document summarizes every single research papers included the file submitted to you. Make sure you summarize every research paper, do not skip any papers. The summary document should be formatted as follows:\n",
    "    # What's New in XXX\n",
    "    ## Randomized Controlled Trials\n",
    "    ## Observational Studies (cohort studies, case-control studies, cross-sectional studies)\n",
    "    ## Basic Science Research\n",
    "    ## Meta-analyses\n",
    "    ## Systematic Reviews\n",
    "    ## Narrative Reviews\n",
    "    ## Case Reports and Case Series\n",
    "    ## Other\n",
    "    One line below each paper's summary, include a brief citation in the format of: \n",
    "    <em>Citation: Title, Journal, PubDate, PMID: [PMID] (URL)</em>\n",
    "    Return your response in markdown format.\"\"\",\n",
    "    tools=[{\"type\": \"file_search\", \"vector_store_ids\": [vector_store.id]}],\n",
    ")\n",
    "# print(response.output_text)\n",
    "\n",
    "# Save the summary as a markdown file\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime(\"%m-%d-%Y\")\n",
    "filename = f\"{today}_{topic}_summary.md\"\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(response.output_text)\n",
    "\n",
    "print(f\"Summary saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
